<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Chris Kelly">
<meta name="dcterms.date" content="2024-02-20">

<title>Chris Kelly Blog - BLUE coefficients: bias and efficiency</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Chris Kelly Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/chris-kelly"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/ccrkelly/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">BLUE coefficients: bias and efficiency</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">OLS</div>
                <div class="quarto-category">least-squares</div>
                <div class="quarto-category">Gauss-markov</div>
                <div class="quarto-category">coefficients</div>
                <div class="quarto-category">BLUE</div>
                <div class="quarto-category">bias</div>
                <div class="quarto-category">efficiency</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Chris Kelly </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 20, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#are-the-ols-coefficients-blue" id="toc-are-the-ols-coefficients-blue" class="nav-link active" data-scroll-target="#are-the-ols-coefficients-blue">Are the OLS coefficients “BLUE”?</a></li>
  <li><a href="#setting-the-scene" id="toc-setting-the-scene" class="nav-link" data-scroll-target="#setting-the-scene">Setting the scene</a></li>
  <li><a href="#bias" id="toc-bias" class="nav-link" data-scroll-target="#bias">Bias</a></li>
  <li><a href="#efficiency" id="toc-efficiency" class="nav-link" data-scroll-target="#efficiency">Efficiency</a>
  <ul class="collapse">
  <li><a href="#coefficient-variance-for-ols" id="toc-coefficient-variance-for-ols" class="nav-link" data-scroll-target="#coefficient-variance-for-ols">Coefficient variance for OLS</a></li>
  <li><a href="#coefficient-variance-assuming-spherical-errors" id="toc-coefficient-variance-assuming-spherical-errors" class="nav-link" data-scroll-target="#coefficient-variance-assuming-spherical-errors">Coefficient variance assuming “spherical errors”</a></li>
  <li><a href="#formulating-an-alternative-unbiased-coefficient" id="toc-formulating-an-alternative-unbiased-coefficient" class="nav-link" data-scroll-target="#formulating-an-alternative-unbiased-coefficient">Formulating an alternative unbiased coefficient</a></li>
  <li><a href="#variance-of-the-alternative-unbiased-coefficient" id="toc-variance-of-the-alternative-unbiased-coefficient" class="nav-link" data-scroll-target="#variance-of-the-alternative-unbiased-coefficient">Variance of the alternative unbiased coefficient</a></li>
  </ul></li>
  <li><a href="#summarising-the-gauss-markov-assumptions" id="toc-summarising-the-gauss-markov-assumptions" class="nav-link" data-scroll-target="#summarising-the-gauss-markov-assumptions">Summarising the Gauss-markov assumptions</a></li>
  </ul>
<div class="quarto-other-links"><h2>Other Links</h2><ul><li><a href="ols_coef_derivation.html"><i class="bi bi-link-45deg"></i>OLS coefficient derivation</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What are we exploring?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Proving that the OLS coefficient is the best linear unbiased estimator.</p>
</div>
</div>
<section id="are-the-ols-coefficients-blue" class="level2">
<h2 class="anchored" data-anchor-id="are-the-ols-coefficients-blue">Are the OLS coefficients “BLUE”?</h2>
<p>We find a unique solution to the set of coefficients that minimize the sum of squared residuals analytically (see its derivation here):</p>
<p><span class="math display">\[
\hat{\beta}^{OLS}=(X^{\intercal}X)^{-1}X^{\intercal}y
\]</span></p>
<p>However, how do we know if these coefficients are the <em>best</em> ones we can estimate?</p>
<p>For the estimated coefficients to be the <em>Best Linear Unbiased Estimator</em> (i.e.&nbsp;“BLUE”):</p>
<ul>
<li>The best estimator has to be <strong>unbiased</strong>: <span class="math inline">\(E[\hat{\beta}^*] = \beta\)</span></li>
<li>And among all possible linear, unbiased estimators, it must have the smallest variance: <span class="math inline">\(V[\hat{\beta}^{*}] &lt; V[\hat{\beta}^{Z}]\)</span></li>
</ul>
<p>We want to ensure our OLS estimate is the best, i.e.&nbsp;that <span class="math inline">\(\hat{\beta}^{OLS} = \hat{\beta}^{*}\)</span>. To achieve this, first we need to confirm it is unbiased. Then given this is true, we can check that the coefficient is most efficient vs all other unbiased estimators.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Gauss Markov Assumptions
</div>
</div>
<div class="callout-body-container callout-body">
<p>Along the way, we will outline the Gauss-Markov assumptions utilised that ensure the OLS coefficient is BLUE.</p>
</div>
</div>
</section>
<section id="setting-the-scene" class="level2">
<h2 class="anchored" data-anchor-id="setting-the-scene">Setting the scene</h2>
<section id="the-true-coefficient-and-model" class="level5">
<h5 class="anchored" data-anchor-id="the-true-coefficient-and-model">The true coefficient and model</h5>
<p><span class="math inline">\(\beta\)</span> is the true (unobserved) relationship between all the relevant explanatory features, <span class="math inline">\(X\)</span>, and their associated observed outcomes, <span class="math inline">\(y\)</span>. In other words, if we observed the entire population of data, it is the relationship we would find.</p>
<p>Concretely, we assume the outcome is a linear function of all its relevant features. This “true model” perfectly predicts the outcome, except for random noise <span class="math inline">\(\epsilon\)</span> that influences the observed outcome: <span class="math inline">\(y = X\beta + \epsilon\)</span></p>
</section>
<section id="the-estimated-coefficient" class="level5">
<h5 class="anchored" data-anchor-id="the-estimated-coefficient">The estimated coefficient</h5>
<p><span class="math inline">\(\hat{\beta}\)</span> is our estimated coefficient for the true relationship <span class="math inline">\(\beta\)</span>. In reality, we estimate <span class="math inline">\(\hat{\beta}\)</span> from the small, finite sample of size <span class="math inline">\(n\)</span> that is collected, not the whole population. Given any random sample could be collected, we can term the coefficient resulting from the optimum estimation proceedure to be <span class="math inline">\(\hat{\beta}^*\)</span>. We want to understand if <span class="math inline">\(\hat{\beta}^{OLS} = \hat{\beta}^*\)</span>.</p>
</section>
<section id="the-expected-estimated-coefficient" class="level5">
<h5 class="anchored" data-anchor-id="the-expected-estimated-coefficient">The expected estimated coefficient</h5>
<p><span class="math inline">\(E[\hat{\beta}]\)</span> is the “expected” estimated coefficient. Imagine we repeat the action of estimating the coefficient <span class="math inline">\(\hat{\beta}\)</span> many times, each time collecting a new sample (where each observation is sampled i.i.d), and recording the value for the estimated coefficient. <span class="math inline">\(E[\hat{\beta}]\)</span> would then be the average of all of those estimated coefficients. If the OLS coefficient is unbiased, then the expected coefficient estimate should be equal to the true one, <span class="math inline">\(E[\hat{\beta}^{OLS}]=\beta\)</span>.</p>
</section>
<section id="the-variance-of-the-estimated-coefficient" class="level5">
<h5 class="anchored" data-anchor-id="the-variance-of-the-estimated-coefficient">The variance of the estimated coefficient</h5>
<p><span class="math inline">\(V[\hat{\beta}]\)</span> is the variance of the estimated coefficient. It determines how much we might expect our estimate <span class="math inline">\(\hat{\beta}\)</span> to differ from the true <span class="math inline">\(\beta\)</span> for any sample drawn. Given the OLS coefficient has been shown to be unbiased, if it is BLUE we expect its variance to be lower than another other unbiased choice <span class="math inline">\(\hat{\beta}^{Z}\)</span>. Concretely, we want to find <span class="math inline">\(V[\hat{\beta}^{OLS}] &lt; V[\hat{\beta}^{Z}]\)</span>.</p>
</section>
</section>
<section id="bias" class="level2">
<h2 class="anchored" data-anchor-id="bias">Bias</h2>
<p>Often our small finite samples of size <span class="math inline">\(n\)</span> are not a perfect reflection of the population they are drawn from. This “sampling error” means we might estimate a different relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(y\)</span> than the true relationship of the population, i.e.&nbsp;<span class="math inline">\(\hat{\beta} \neq \beta\)</span>.</p>
<p>However, we should expect our estimated coefficient to be equal to the true value on average. This means we do not want to have a bias towards the estimate being systematically too small or too large, for example. In other words, if we repeated the whole proceedure thousands of times (each time taking new samples, and estimating a coefficient from the new sample) then the average of all the estimated coefficients values should be equal to the true value, i.e.&nbsp;<span class="math inline">\(E[\hat{\beta}] = \beta\)</span>.</p>
<p>Recall that we believe there is a true model that follows the form:</p>
<p><span class="math display">\[
y = X\beta + \epsilon
\]</span></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
GM1: Linearity <a name="GM1"></a>
</div>
</div>
<div class="callout-body-container callout-body">
<p>The formula above relies on the first Gauss-Markov assumption - that the dependent variable <span class="math inline">\(y\)</span> is assumed to be a linear function of the variables <span class="math inline">\(X\)</span>. Note that implies that the proper functional form has been selected (i.e.&nbsp;the relationship is linear) and there are no omitted variables - a huge assumption!</p>
</div>
</div>
<p>If we substitute this into our estimated coefficient:</p>
<p><span class="math display">\[
\displaylines{
\begin{align}
\hat{\beta}^{OLS} &amp; = (X^{\intercal}X)^{-1}X^{\intercal}y
\\ &amp; = (X^{\intercal}X)^{-1}X^{\intercal}(X\beta+\epsilon)
\\ &amp; = (X^{\intercal}X)^{-1}X^{\intercal}X\beta+(X^{\intercal}X)^{-1}X^{\intercal}\epsilon
\\ &amp; = \beta+(X^{\intercal}X)^{-1}X^{\intercal}\epsilon
\end{align}
}
\]</span></p>
<p>we show that the estimated coefficient <span class="math inline">\(\hat{\beta}^{OLS}\)</span> will differ from the true value depending on the random error <span class="math inline">\(\epsilon\)</span> associated with the particular finite sample collected.</p>
<p>Now let’s now take the expectation, to determine when the coefficient is unbiased. In other words, what is the “average” coefficient if we took the sample many times: <span class="math display">\[
\displaylines{
\begin{align}
E[\hat{\beta}^{OLS}]
&amp; = \beta +(X^{\intercal}X)^{-1}X^{\intercal}E[\epsilon]
\\ &amp; = \beta &amp; \iff E[\epsilon] &amp; = 0
\end{align}
\\
}
\]</span></p>
<p>We find that the coefficient is unbiased as long as the expected error is also zero.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
GM2: Strict Exogeneity <a name="GM2"></a>
</div>
</div>
<div class="callout-body-container callout-body">
<p>The second Gauss-Markov assumption is strict exogeneity, where the expected error is zero for all feature values: <span class="math inline">\(E[\epsilon|X] = 0\)</span>. By definition, the weaker exogeneity statement of <span class="math inline">\(E[\epsilon] = 0\)</span> is implied by having the expected error conditional being equal to zero.</p>
</div>
</div>
</section>
<section id="efficiency" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="efficiency">Efficiency</h2>
<p>To be the “best”, the OLS estimator also needs to be <strong>efficient</strong>. This means that it has the lowest variance of all unbiased estimators. This section looks to prove this.</p>
<section id="coefficient-variance-for-ols" class="level3">
<h3 class="anchored" data-anchor-id="coefficient-variance-for-ols">Coefficient variance for OLS</h3>
<p>First, let’s derive the variance from the coefficients estimated using OLS, termed <span class="math inline">\(V[\hat{\beta}^{OLS}]\)</span>. As before, we substitute the true model <span class="math inline">\(y = X\beta + \epsilon\)</span> into the coefficient estimated through OLS:</p>
<p><span class="math display">\[
\displaylines{
\begin{align}
\hat{\beta}^{OLS}-\beta
&amp; = \beta +  ((X^{\intercal}X)^{-1}X^{\intercal}\epsilon) - \beta \\
&amp; = (X^{\intercal}X)^{-1}X^{\intercal}\epsilon
\\ \\
\therefore
(\hat{\beta}^{OLS}-\beta)(\hat{\beta}^{OLS}-\beta)^{\intercal}
&amp; = ((X^{\intercal}X)^{-1}X^{\intercal}\epsilon)((X^{\intercal}X)^{-1}X^{\intercal}\epsilon)^{\intercal}
\\ &amp; =
(X^{\intercal}X)^{-1}X^{\intercal}\epsilon\epsilon^{\intercal}X(X^{\intercal}X)^{-1} \\ \\
\therefore
V(\hat{\beta}^{OLS}) &amp; = E[(\hat{\beta}^{OLS}-\beta)(\hat{\beta}^{OLS}-\beta)^{\intercal}]
\\ &amp; =
(X^{\intercal}X)^{-1}X^{\intercal}E[\epsilon\epsilon^{\intercal}]X(X^{\intercal}X)^{-1}
\end{align}
}
\]</span></p>
<p>This is sometimes called the sandwich estimator - post soon to follow on this!</p>
</section>
<section id="coefficient-variance-assuming-spherical-errors" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="coefficient-variance-assuming-spherical-errors">Coefficient variance assuming “spherical errors”</h3>
<p>We can simplify this further by appling some assumptions to the estimated error variance <span class="math inline">\(E[\epsilon\epsilon^{\intercal}]\)</span>:</p>
<p><span class="math display">\[
\displaylines{
\begin{align}
E[\epsilon \epsilon^{\intercal}] &amp; =  
\begin{bmatrix}
E[\epsilon_1^2] &amp; \cdots &amp; E[\epsilon_1\epsilon_n] \\
\vdots &amp; \ddots &amp; \vdots \\
E[\epsilon_n\epsilon_1] &amp; \cdots &amp; E[\epsilon_n^2]
\end{bmatrix} \\ \\
&amp; = \begin{bmatrix}
\frac{1}{n}\sum_{i=1}^{n}{\epsilon_i^2} &amp; \cdots &amp; 0 \\
\vdots &amp; \ddots &amp; \vdots \\
0 &amp; \cdots &amp; \frac{1}{n}\sum_{i=1}^{n}{\epsilon_i^2}
\end{bmatrix} \\ \\
&amp; = \begin{bmatrix}
\hat{\sigma}^2 &amp; \cdots &amp; 0 \\
\vdots &amp; \ddots &amp; \vdots \\
0 &amp; \cdots &amp; \hat{\sigma}^2
\end{bmatrix} \\ \\
&amp; = \hat{\sigma}^2I
\end{align}
}
\]</span></p>
<p>How can we jump to this result? Well we are making two assumptions:</p>
<ol type="1">
<li><strong>No serial correlation</strong>: <span class="math inline">\(\rho_{\epsilon_{i},\epsilon_{i \neq j}} = 0\)</span>. No correlation between sample errors means that <span class="math inline">\(E[\epsilon_i \epsilon_{j \neq i}] = 0\)</span>, and hence the off-diagonals of the error covariance matrix are zero.</li>
<li><strong>Homoskedasticity</strong>: the assumption of uniform error variance for all samples means that <span class="math inline">\(V[\epsilon_i^2] = V[\epsilon_{j \neq i}^2] = \hat{\sigma}^2\)</span>. And our best approximation for <span class="math inline">\(\hat{\sigma}^2\)</span> is simply taking the average squared error: <span class="math inline">\(\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^{n}{\epsilon_i^2}\)</span></li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
GM3: Spherical errors <a name="GM3"></a>
</div>
</div>
<div class="callout-body-container callout-body">
<p>The third Gauss-Markov assumption is spherical errors, <span class="math inline">\(E[\epsilon\epsilon^{\intercal}|X] = 0\)</span>. This means that the outer product of the expected errors is a scalar matrix, which implies no serial correlation and homoskedasticity.</p>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p>It is especially important to make the right assumptions about <span class="math inline">\(E[\epsilon\epsilon^{\intercal}|X]\)</span> as it impacts where our estimate of the standard errors is correct! We will dive into what happens to SE if we violate these assumptions in another post.</p>
</div></div><p>Since we now see that <span class="math inline">\(\hat{\sigma}^2\)</span> is a scalar matrix, we can thus simplfy the variance formula further:</p>
<p><span class="math display">\[
\displaylines{
\begin{align}
V(\hat{\beta}^{OLS}) &amp; =
(X^{\intercal}X)^{-1}X^{\intercal}E[\epsilon\epsilon^{\intercal}]X(X^{\intercal}X)^{-1}
\\ &amp; =
(X^{\intercal}X)^{-1}X^{\intercal} \hat{\sigma}^2I X(X^{\intercal}X)^{-1}
\\ &amp; =
\hat{\sigma}^2
\cancel{(X^{\intercal}X)^{-1}}
\cancel{X^{\intercal} X}
(X^{\intercal}X)^{-1}
\\ &amp; = \hat{\sigma}^2(X^{\intercal}X)^{-1}
\end{align}
}
\]</span></p>
</section>
<section id="formulating-an-alternative-unbiased-coefficient" class="level3">
<h3 class="anchored" data-anchor-id="formulating-an-alternative-unbiased-coefficient">Formulating an alternative unbiased coefficient</h3>
<p>Next step - lets formulate another estimator, <span class="math inline">\(\hat{\beta}^{z}\)</span>, which differs from <span class="math inline">\(\hat{\beta}^{OLS}\)</span> by a non-zero matrix <span class="math inline">\(A\)</span>. See how they both differ below:</p>
<p><span class="math display">\[
\displaylines{
\begin{align}
\hat{\beta}^{OLS} &amp; =(X^{\intercal}X)^{-1}X^{\intercal}y \\
\hat{\beta}^{Z} &amp; =\left((X^{\intercal}X)^{-1}X^{\intercal}+A\right)y
\end{align}
}
\]</span></p>
<p>Now we need to ensure this new estimator is not biased. So by taking the expectation in the same was as for OLS…</p>
<p><span class="math display">\[
\displaylines{
\begin{align}
E[\hat{\beta}^{Z}] &amp; = E\left[ \left((X^{\intercal}X)^{-1}X^{\intercal}+A\right)y \right]
\\ &amp; = \left((X^{\intercal}X)^{-1}X^{\intercal}+A\right)(X\beta+ \cancel{E\left[\epsilon \right]}) &amp; \because E[\epsilon] = 0
\\ &amp; = (X^{\intercal}X)^{-1}X^{\intercal}X\beta+AX\beta
\\ &amp; = \beta+AX\beta
\end{align}
}
\]</span></p>
<p>So the estimator is only unbiased iff <span class="math inline">\(AX=0\)</span>. This is important to note when comparing the variance between unbiased coefficients - see below!</p>
</section>
<section id="variance-of-the-alternative-unbiased-coefficient" class="level3">
<h3 class="anchored" data-anchor-id="variance-of-the-alternative-unbiased-coefficient">Variance of the alternative unbiased coefficient</h3>
<p>Just like before, we calculate the variance:</p>
<p><span class="math display">\[
\displaylines{
\begin{align}
V[\hat{\beta}^{Z}]
&amp; = V\left[ \left((X^{\intercal}X)^{-1}X^{\intercal}+A\right)y \right]
\\ &amp; = \left((X^{\intercal}X)^{-1}X^{\intercal}+A\right) V[y] \left((X^{\intercal}X)^{-1}X^{\intercal}+A\right)^{\intercal}
\\ &amp; = \hat{\sigma}^2 \left((X^{\intercal}X)^{-1}X^{\intercal}+A\right) \left((X^{\intercal}X)^{-1}X^{\intercal}+A\right)^{\intercal}
&amp; \because E[\epsilon \epsilon^{\intercal}|X] = 0
\\ &amp; = \hat{\sigma}^2\left((X^{\intercal}X)^{-1}X^{\intercal}+A\right) \left(X(X^{\intercal}X)^{-1}+A^{\intercal}\right)
\\ &amp; = \hat{\sigma}^2 \left(
(X^{\intercal}X)^{-1}X^{\intercal} X(X^{\intercal}X)^{-1} + AX(X^{\intercal}X)^{-1} + (X^{\intercal}X)^{-1}X^{\intercal}A^{\intercal} + AA^{\intercal}
\right)
\\ &amp; = \hat{\sigma}^2
(X^{\intercal}X)^{-1} + \hat{\sigma}^2AA^{\intercal}
&amp; \because AX = 0
\\ &amp; = V[\beta^{OLS}] + \hat{\sigma}^2AA^{\intercal}
\end{align}
}
\]</span></p>
<p>Now since AA is surely a positive semi-definite matrix, then we know that <span class="math inline">\(V[\hat{\beta}^{Z}] &gt; V[\hat{\beta}^{OLS}]\)</span>.</p>
<p>We have shown that <span class="math inline">\(\hat{\beta}^{OLS}\)</span> has the smallest variance among all unbiased estimators!</p>
</section>
</section>
<section id="summarising-the-gauss-markov-assumptions" class="level2">
<h2 class="anchored" data-anchor-id="summarising-the-gauss-markov-assumptions">Summarising the Gauss-markov assumptions</h2>
<p>Along the way, we showed where assumptions were needed to ensure the OLS coefficient estimation is BLUE.</p>
<p>We actually missed one out, but it is actually quite trivial to see from the OLS coefficient formula:</p>
<p><span class="math display">\[
\hat{\beta}^{OLS}=(X^{\intercal}X)^{-1}X^{\intercal}y
\]</span></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
GM4: Full rank <a name="GM4"></a>
</div>
</div>
<div class="callout-body-container callout-body">
<p>The matrix <span class="math inline">\(X\)</span> must be of full rank <span class="math inline">\(k\)</span>, so that it is possible to invert the matrix <span class="math inline">\(X^{\intercal}X\)</span>. This is equivalent to having no perfect multi-collinearity.</p>
</div>
</div>
<p>We have now collected our full set of Gauss-Markov assumptions required for the OLS coefficient to be BLUE:</p>
<ol type="1">
<li><a href="#GM1">Linearity</a></li>
<li><a href="#GM2">Strict Exogeneity</a></li>
<li><a href="#GM3">Spherical Errors</a></li>
<li><a href="#GM4">Full rank</a></li>
</ol>
<!-- However, let's first derive the need for exogeneity from the math above, as this is required: -->
<!-- ### Orthogonality of residuals and features

From the outputs from [step 2 above](##partially-differentiate-rss-with-respect-to-beta), we can also derive the orthogonality between the features and the residuals. -->
<!-- $$
\displaylines{
\cancel{2}X^{\intercal}y +  \cancel{2}((X^{\intercal}X)\hat{\beta})=0 \\
\therefore -X^{\intercal}(y -X^{\intercal}\hat{\beta}) =
X^{\intercal}\hat{\epsilon} = 0 \\
}
$$

What does this mean? Well there is no linear relationship between the residuals and any feature in $X$:, so $E[\hat{\epsilon}|X] = 0$.

In order for this to be true for the intercept (the first column in $X$, a vector of ones), we must find that the sum of residuals (and equivalently the mean residual) is zero: $E[\hat{\epsilon}] = 0$

Note the key difference between residuals and true error.The residuals are guaranteed to be orthogonal, but not the errors. -->
<!-- ::: {.column-margin}
Recall the confidence interval of a coefficient using the normal approximation:

$$
\hat{\beta} \pm t_{n-k,1-\alpha/2} \times \sigma_{\hat{\beta}}
$$

In other words, if we repeated the whole proeedure thousands of times (taking new samples, estimating a coefficient from this sample, and estimated its 95% confidence interval) then we should find that the true value lies in 95% of these confidence interval estimates.
::: -->
<!-- :::{.column-margin}
Conditional homoskedasticity means that even for different $x_i$, the variance of $\epsilon_i$ is constant $\sigma^2$.

. Unconditional homoskedasticity is a weaker statement, in that you could have 𝐸(𝜖2𝑖)=𝜎2
 but 𝐸(𝜖2𝑖|𝐱𝑖)≠𝜎2
; Examples 2.6 (page 127) illustrates this. It also perhaps answers the question of the overlap between homo- and heteroskedasticity: it gives an example where there is unconditional homoskedasticity as well as conditional heteroskedasticity.
::: -->
<!-- conditional homoskedasticity implies unconditional homoskedasticity
This means applying one of the gauss-markov assumptions: $E[\epsilon] -->
<!-- In other words, the coefficient is unbiased iff:

* There is no endogeneity: $E[X^{\intercal}\epsilon] = 0$
* There is no systematic error in the coefficients: $E[\epsilon] = 0$ -->


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>